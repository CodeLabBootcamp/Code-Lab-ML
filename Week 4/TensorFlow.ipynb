{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkjh195znZ6I"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBCGaZXEyn0N"
      },
      "source": [
        "## Tensors \n",
        "In mathematics, a tensor is an algebraic object that describes a (multilinear) relationship between sets of algebraic objects related to a vector space. Objects that tensors may map between include vectors and scalars, and even other tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cOg1x6VwXFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8782cc8-a964-40ab-965a-6a63e31f39ab"
      },
      "source": [
        "def describe_tensor(name, tensor):\n",
        "  print(f'{name}\\nShape:{tensor.shape}\\nData Type: {tensor.dtype}\\n{tensor}')\n",
        "  print('\\n', '-'*50, '\\n')\n",
        "\n",
        "\n",
        "\n",
        "tensor_of_ones=tf.ones([3,4])\n",
        "tensor_of_zeros=tf.zeros([3,4])\n",
        "random_normal_tensor=tf.random.normal(shape=[2,1,3])\n",
        "random_uniform_tensor=tf.random.uniform(shape=[2,1,3])\n",
        "\n",
        "describe_tensor(\"Tensor of Ones\", tensor_of_ones)\n",
        "describe_tensor(\"Tensor of Zeros\", tensor_of_zeros)\n",
        "describe_tensor(\"Tensor of Normal Random Numbers\", random_normal_tensor)\n",
        "describe_tensor(\"Tensor of Uniform Random Numbers\", tensor_of_zeros)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor of Ones\n",
            "Shape:(3, 4)\n",
            "Data Type: <dtype: 'float32'>\n",
            "[[1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]\n",
            " [1. 1. 1. 1.]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor of Zeros\n",
            "Shape:(3, 4)\n",
            "Data Type: <dtype: 'float32'>\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor of Normal Random Numbers\n",
            "Shape:(2, 1, 3)\n",
            "Data Type: <dtype: 'float32'>\n",
            "[[[ 0.48056725  0.7534062   0.12173042]]\n",
            "\n",
            " [[-0.6253721   0.47919193  0.6198538 ]]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor of Uniform Random Numbers\n",
            "Shape:(3, 4)\n",
            "Data Type: <dtype: 'float32'>\n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSagNGqI2b4K"
      },
      "source": [
        "### Constants\n",
        "\n",
        "In TensorFlow when you declare a constant , its value can't be changed in the future (also the initialization should be with a value, not with operation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQxe1BhDwfsF",
        "outputId": "2de3b245-77fb-424f-d85d-39ea978db903"
      },
      "source": [
        "constant_1=tf.constant([10,20,45],tf.float32)\n",
        "\n",
        "describe_tensor(\"Constant Tensor\", constant_1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Constant Tensor\n",
            "Shape:(3,)\n",
            "Data Type: <dtype: 'float32'>\n",
            "[10. 20. 45.]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuTPc_u33_Db"
      },
      "source": [
        "### Basic Math  on tensors \n",
        "You can do basic math on tensors including addition, element-wise multiplication, matrix multiplication and more.\n",
        "\n",
        "* **Tensors Addition**\n",
        "\n",
        "Given two input tensors, the **tf.add** operation computes the sum for every element in the tensor.\n",
        "\n",
        "* **Tensors Element-Wise Multiplication**\n",
        "\n",
        "Given two input tensors, the **tf.multiply** operation computes the multiply for every element in the tensor.\n",
        "\n",
        "* **Tensor Multiplication**\n",
        "\n",
        "in tensorflow the **tf.matmul**, tensor multiplication is a binary operation that produces a tensor from two tensors. For tensor multiplication, the number of columns in the first tensor must be equal to the number of rows in the second tensor.\n",
        "\n",
        "A full list of operations can be found here: https://www.tensorflow.org/api_docs/python/tf/math\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wOQK29rw6OY",
        "outputId": "ae73fb40-5977-40d5-bc07-3d9edd72e38c"
      },
      "source": [
        "a=tf.constant([1,2,3,4],shape=[2,2])\n",
        "b=tf.constant([5,6,7,8],shape=[2,2])\n",
        "\n",
        "describe_tensor(\"Tensor a\", a)\n",
        "describe_tensor(\"Tensor b\", a)\n",
        "describe_tensor(\"Tensor a + b\", tf.add(a, b))\n",
        "describe_tensor(\"Tensor a * b\", tf.multiply(a, b))\n",
        "describe_tensor(\"Tensor ab (matrix multiplication)\", tf.matmul(a, b))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor a\n",
            "Shape:(2, 2)\n",
            "Data Type: <dtype: 'int32'>\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor b\n",
            "Shape:(2, 2)\n",
            "Data Type: <dtype: 'int32'>\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor a + b\n",
            "Shape:(2, 2)\n",
            "Data Type: <dtype: 'int32'>\n",
            "[[ 6  8]\n",
            " [10 12]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor a * b\n",
            "Shape:(2, 2)\n",
            "Data Type: <dtype: 'int32'>\n",
            "[[ 5 12]\n",
            " [21 32]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "Tensor ab (matrix multiplication)\n",
            "Shape:(2, 2)\n",
            "Data Type: <dtype: 'int32'>\n",
            "[[19 22]\n",
            " [43 50]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkBIiH6Uu2DK"
      },
      "source": [
        "More tensor operations (again, the full list of math operations can be found here: https://www.tensorflow.org/api_docs/python/tf/math)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSwsfc26xksm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67ef54c6-4323-4bca-f7df-aa4881ce2193"
      },
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "describe_tensor(\"Tensor c\", c)\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "print('-'*50)\n",
        "\n",
        "# Find the index of the largest value\n",
        "print(tf.argmax(c)) \n",
        "print('-'*50)\n",
        "\n",
        "# Find the mean of the tensor\n",
        "print(tf.reduce_mean(c))\n",
        "print('-'*50)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor c\n",
            "Shape:(2, 2)\n",
            "Data Type: <dtype: 'float32'>\n",
            "[[ 4.  5.]\n",
            " [10.  1.]]\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n",
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "--------------------------------------------------\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
            "--------------------------------------------------\n",
            "tf.Tensor(5.0, shape=(), dtype=float32)\n",
            "--------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-D7m809xsRR"
      },
      "source": [
        "### Variables\n",
        "Variables are created and tracked via the tf.Variable class. A tf.Variable represents a tensor whose value can be changed by running ops on it. Specific ops allow you to read and modify the values of this tensor. Higher level libraries like tf.keras use tf.Variable to store model parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRpZ5X_gx9KS"
      },
      "source": [
        "my_constant = tf.constant([[1.0, 2.0,3.0], [4.0, 5.0,6.0]])\n",
        "my_variable = tf.Variable(my_constant)\n",
        "\n",
        "# Variables can be used with all kinds of types, just like Tensors\n",
        "\n",
        "bool_variable = tf.Variable([False, False, False, True])\n",
        "complex_variable = tf.Variable([5 + 4j, 6 + 1j])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GxKzF2WzAYZ"
      },
      "source": [
        "A variable looks and acts like a tensor, and, in fact, is a data structure backed by a tf.Tensor. Like tensors, they have a dtype and a shape, and can be exported to NumPy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQNRSdqS-0RF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3493ac9a-3179-4bed-862d-212856433609"
      },
      "source": [
        "describe_tensor(\"Variable Tensor\", my_variable)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable Tensor\n",
            "Shape:(2, 3)\n",
            "Data Type: <dtype: 'float32'>\n",
            "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "\n",
            " -------------------------------------------------- \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qQTBpV55r0H"
      },
      "source": [
        "Most tensor operations work on variables as expected, although variables cannot be reshaped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te-9NT0vzC9d",
        "outputId": "0fb79a73-7fbe-4950-8f6a-f6322edc1b1c"
      },
      "source": [
        "print(\"Variable:\", my_variable)\n",
        "print('\\n')\n",
        "print(\"Variable as Tensor:\", tf.convert_to_tensor(my_variable))\n",
        "print('\\n')\n",
        "print(\"Index of highest value:\", tf.argmax(my_variable))\n",
        "print('\\n')\n",
        "\n",
        "# This creates a new tensor; it does not reshape the variable.\n",
        "print(\"Copying and reshaping: \", tf.reshape(my_variable, ([1,6])))\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable: <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "\n",
            "\n",
            "Variable as Tensor: tf.Tensor(\n",
            "[[1. 2. 3.]\n",
            " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
            "\n",
            "\n",
            "Index of highest value: tf.Tensor([1 1 1], shape=(3,), dtype=int64)\n",
            "\n",
            "\n",
            "Copying and reshaping:  tf.Tensor([[1. 2. 3. 4. 5. 6.]], shape=(1, 6), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whpwhYLK7syp"
      },
      "source": [
        "If you use a variable like a tensor in operations, you will usually operate on the backing tensor.\n",
        "\n",
        "Creating new variables from existing variables duplicates the backing tensors. Two variables will not share the same memory.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "197id_vf5vqB",
        "outputId": "bea476b5-2fe6-427e-e218-2534465027df"
      },
      "source": [
        "a = tf.Variable([2.0, 3.0])\n",
        "# Create b based on the value of a\n",
        "b = tf.Variable(a)\n",
        "a.assign([5, 6])\n",
        "\n",
        "# a and b are different\n",
        "print(a.numpy())\n",
        "print(b.numpy())\n",
        "\n",
        "# There are other versions of assign\n",
        "print(a.assign_add([2,3]).numpy())  # [7. 9.]\n",
        "print(a.assign_sub([7,9]).numpy())  # [0. 0.]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5. 6.]\n",
            "[2. 3.]\n",
            "[7. 9.]\n",
            "[0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycyV4obMuy5N"
      },
      "source": [
        "## Neural Networks in TensorFlow \n",
        "\n",
        "TensorFlow is used to build neural networks, a neural network is a set of layers, each layer had a number of neurons, these neurons can be of different architectures, for this tutorial we will focus on `Dense` layers (aka Fully Connected Layers).\n",
        "\n",
        "These layers are defined in `tf.keras.layers` module, let's take a look at how a `Dense` layer work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIEIOMIgGkHr",
        "outputId": "b0535577-fccb-47fb-a579-39032e9e5ebb"
      },
      "source": [
        "# This layer has a single neuron and a sigmoid activation function. Basically, this layer is doing Logstic Regression\n",
        "layer_1 = tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "\n",
        "# Let's pass a Tensor through the layer\n",
        "\n",
        "input_1 = tf.Variable([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
        "output_1 = layer_1(input_1)\n",
        "\n",
        "print(\"Input\\n\", my_variable)\n",
        "print(\"Output\\n\", output_1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input\n",
            " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
            "array([[1., 2., 3.],\n",
            "       [4., 5., 6.]], dtype=float32)>\n",
            "Output\n",
            " tf.Tensor(\n",
            "[[0.922564 ]\n",
            " [0.9873135]], shape=(2, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeG29eb2INWl"
      },
      "source": [
        "In the previous cell, each row (which represents a single example in a dataset) was passed through a Logistic Regression unit, we can examine the weight and bias of the Logistic Function and see how the output came to be"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAn_ZdneHXef",
        "outputId": "0066b63b-2e23-417b-8479-c9dd258c86a0"
      },
      "source": [
        "print(\"Weights:\\n\", layer_1.kernel)\n",
        "print('-'*50)\n",
        "print(\"Bias:\\n\", layer_1.bias)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weights:\n",
            " <tf.Variable 'dense/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
            "array([[-0.11411059],\n",
            "       [-0.3727402 ],\n",
            "       [ 1.1124321 ]], dtype=float32)>\n",
            "--------------------------------------------------\n",
            "Bias:\n",
            " <tf.Variable 'dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jhSw5zJwQb7"
      },
      "source": [
        "### MNIST Example\n",
        "\n",
        "The MNIST database is a large database of handwritten digits that is commonly used for training various image processing systems. This database it built-into TensorFlow, we can load it from the `tf.keras.datasets` module.\n",
        "\n",
        "This function returns two tuples, one for the training set and one for the testing set. The dataset has 60,000 example for training and 10,000 for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4caA4xUx4NA",
        "outputId": "f3c471fe-5712-408d-df80-07e6ddc11b24"
      },
      "source": [
        "# Load mnist dataset \n",
        "(x_train,y_train),(x_test,y_test)=tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkKWeemSa7a4"
      },
      "source": [
        "Let's take a look at an example choosen at random, rerun this cell to look at different samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "7AwYTEMva6ii",
        "outputId": "8b37b505-00b8-4c16-f44a-c38f8796ada9"
      },
      "source": [
        "index = np.random.randint(0, len(y_train))\n",
        "\n",
        "print('Label',y_train[index])\n",
        "# We'll show the image using matplotlib\n",
        "plt.imshow(x_train[index], cmap='gray')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f71f91fdc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72BE2K9VbViF"
      },
      "source": [
        "#### One Hot Encoding\n",
        "\n",
        "One hot encoding is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\n",
        "\n",
        "Instead of the target being a singular value (i.e. 3), it becomes a vector that's size is equal to the number of unique targets in the dataset, with all values being 0 except for one which would represent the original singluar value.\n",
        "\n",
        "In case of having 5 different targets, the one-hot vector will be of length 5, look at the table below to see how the original values are represented as one hot encoded vectors\n",
        "\n",
        "| Before One Hot Encoding | After One Hot Encoding |\n",
        "|-------------------------|------------------------|\n",
        "| 0                       | [1, 0, 0, 0, 0]        |\n",
        "| 1                       | [0, 1, 0, 0, 0]        |\n",
        "| 2                       | [0, 0, 1, 0, 0]        |\n",
        "| 3                       | [0, 0, 0, 1, 0]        |\n",
        "| 4                       | [0, 0, 0, 0, 1]        |\n",
        "\n",
        "\n",
        "We can one-hot encode the targets using `tf.one_hot` method, let's do that for the MNIST dataset target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgEUCPq8bu5w"
      },
      "source": [
        "# Depth is the total number of possible cateogries, we can also use len(set(y_train)) to get the number of unique targets automatically\n",
        "y_train_onehot = tf.one_hot(y_train, depth=10) \n",
        "y_test_onehot = tf.one_hot(y_test, depth=10)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4jxzzSpcDX8"
      },
      "source": [
        "Now let's take a look at random samples from the targets before and after one hot encoding, rerun the cell to examine different values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEe7kZE4cDHX",
        "outputId": "189fa95f-044a-4c73-f608-c9a7decb1e26"
      },
      "source": [
        "index = np.random.randint(0, len(y_train))\n",
        "print(y_train[index])\n",
        "print(y_train_onehot[index])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "tf.Tensor([0. 0. 0. 0. 0. 0. 0. 1. 0. 0.], shape=(10,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z_cF8RmKrqJ"
      },
      "source": [
        "#### `tf.keras.Sequential`\n",
        "The sequential API allows you to create models by stacking layers on top of eachother, where the output of each layer becomes the input for the following layer.\n",
        "\n",
        "There are three types of layers, the input layer which should match the number of features or the shape of you training examples, and the output layer which should match the desired output, and hidden layers in between to do the heavy lifting.\n",
        "\n",
        "Mostly, the output layer can be defined as such:\n",
        "\n",
        "\n",
        "*   Regression Problems: 1 unit with no activation function `tf.keras.layers.Dense(1)`\n",
        "*   Binomial Classification Problems: 1 unit with sigmoid activation function `tf.keras.layers.Dense(1, activation='sigmoid')`\n",
        "*   Multinomial Classification Problems: n units (equal to the number of possible classes/outputs) with softmax activation function `tf.keras.layers.Dense(1, activation='softmax')`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNiPGBi9N_H7"
      },
      "source": [
        "Let's uild the tf.keras.Sequential model by stacking layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAYrWtMO7tQK"
      },
      "source": [
        "# Create the Sequential model using Leras \n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Input(shape=(28,28)), # Input shape of the samples, in this case the images are represented as 28x28 matrix\n",
        "                           tf.keras.layers.Flatten(), # This flattens the matrix into a vector, the shape will become (784) instead of (28,28)\n",
        "                           tf.keras.layers.Dense(units=128,activation='relu',name='layer_1'), # Defining a name for each layer makes debugging easier\n",
        "                           tf.keras.layers.Dense(units=128,activation='relu',name='layer_2'),\n",
        "                           tf.keras.layers.Dense(units=10,activation='softmax', name='output_layer')\n",
        "])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jnp7QSfKNtE_"
      },
      "source": [
        "The `summary()` method prints the neural network layers and parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJeeB9RFwfn1",
        "outputId": "af88adce-b984-469d-f597-fa997671ad41"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_2 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "layer_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "layer_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgtiN8VIjlnb"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_ie9CU42S4k"
      },
      "source": [
        "Choose an optimizer and loss function for training.\n",
        "\n",
        "For the optimizer, we will almost always use Adam optimizer because it's been proven to be superior for most deep learning tasks, alternatively we can use other optimizers like SDG and RMSProp. A full list of available optimizers can be found here: https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\n",
        "\n",
        "\n",
        "As for the loss function, it depends on the task, but here are some general rules of thumb that are applicable to most cases: \n",
        "\n",
        "*   Regression Problems: `tf.losses.MeanSquaredError()` or `tf.losses.MeanAbsoluteError()`\n",
        "*   Binomial Classification Problems: `tf.losses.BinaryCrossentropy()`.\n",
        "*   Multinomial Classification Problems: `tf.losses.CategoricalCrossentropy()`.\n",
        "\n",
        "A full list of losses can be found here: https://www.tensorflow.org/api_docs/python/tf/keras/losses\n",
        "\n",
        "\n",
        "As for the metrics, we can use the metrics sutiable for the task at hand, a full list of metrics can be found here: https://www.tensorflow.org/api_docs/python/tf/keras/metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDmis9XaN5UB"
      },
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), loss=tf.losses.MeanSquaredError(), metrics=[tf.metrics.CategoricalAccuracy()])"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QU5ER2XL07bW",
        "outputId": "ab771a51-d20e-4f86-bb84-ebd0c92de6a4"
      },
      "source": [
        "# Train the model for 10 epochs \n",
        "# the fit function returns history variable which contains the losses and other metrics for all epoches durning training\n",
        "model.fit(x_train, y_train_onehot, epochs=10, validation_data=(x_test, y_test_onehot))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1803 - categorical_accuracy: 0.0983 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1800 - categorical_accuracy: 0.1001 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1799 - categorical_accuracy: 0.1006 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1802 - categorical_accuracy: 0.0988 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1804 - categorical_accuracy: 0.0980 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1799 - categorical_accuracy: 0.1003 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1805 - categorical_accuracy: 0.0976 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1802 - categorical_accuracy: 0.0992 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1803 - categorical_accuracy: 0.0985 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1798 - categorical_accuracy: 0.1011 - val_loss: 0.1804 - val_categorical_accuracy: 0.0980\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
